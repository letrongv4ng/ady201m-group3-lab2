{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1a9c903",
   "metadata": {},
   "source": [
    "\n",
    "# 2.3 — Từ hiểu dữ liệu đến bước chuẩn bị\n",
    "\n",
    "Ở đây, nhóm sẽ tìm hiểu về phân phối và mối quan hệ trong dữ liệu, sau đó kiểm định dữ liệu rồi mới làm sạch trước khi xây dựng đặc trưng dựa trên dữ liệu đó."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92b09ac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c04a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, re\n",
    "from pathlib import Path\n",
    "\n",
    "def slugify(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"-\", str(s).lower()).strip(\"-\")\n",
    "\n",
    "CONFIG_PATH = \"../.lab2_config.json\"\n",
    "CITY = None\n",
    "city_slug = None\n",
    "DAYS = None\n",
    "\n",
    "if os.path.exists(CONFIG_PATH):\n",
    "    with open(CONFIG_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        cfg = json.load(f)\n",
    "    CITY = cfg.get(\"CITY\")\n",
    "    city_slug = cfg.get(\"city_slug\") or (slugify(CITY) if CITY else None)\n",
    "    DAYS = cfg.get(\"DAYS\")\n",
    "    print(f\"[config] CITY={CITY} | city_slug={city_slug} | DAYS={DAYS}\")\n",
    "else:\n",
    "    print(\"[config] Not found, will auto-detect from files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5adb637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, pathlib, re, os\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "RAW_DIR = \"../data/raw\"\n",
    "INTERIM_DIR = f\"../data/interim/{city_slug}\"\n",
    "PROCESSED_DIR = f\"../data/processed/{city_slug}\"\n",
    "Path(INTERIM_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(PROCESSED_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def slugify(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"-\", str(s).lower()).strip(\"-\")\n",
    "\n",
    "try:\n",
    "    CITY  \n",
    "except NameError:\n",
    "    CITY = None  \n",
    "\n",
    "city_slug = slugify(CITY) if CITY else None\n",
    "\n",
    "candidates = []\n",
    "if city_slug:\n",
    "    candidates = sorted(glob(f\"{RAW_DIR}/{city_slug}/forecast_*.csv\"))\n",
    "if not candidates:\n",
    "    candidates = sorted(glob(f\"{RAW_DIR}/**/forecast_*.csv\", recursive=True))\n",
    "\n",
    "src = candidates[-1] if candidates else None\n",
    "print(\"Using source:\", src)\n",
    "\n",
    "if not src:\n",
    "    print(\"No valid source found. Run 2.2 first or check internet.\")\n",
    "else:\n",
    "    df = pd.read_csv(src)\n",
    "\n",
    "    if not city_slug:\n",
    "        if \"city\" in df.columns and len(df):\n",
    "            city_slug = slugify(df[\"city\"].iloc[0])\n",
    "        else:\n",
    "            city_slug = Path(src).parent.name  \n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "    # ===== Schema check =====\n",
    "    expected = {\"date\",\"temp_max\",\"temp_min\",\"precipitation_sum\",\"wind_speed_10m_max\",\"city\",\"lat\",\"lon\",\"source\"}\n",
    "    missing = expected - set(df.columns)\n",
    "    assert not missing, f\"Missing columns: {missing}\"\n",
    "\n",
    "    issues = []\n",
    "    for col in [\"temp_max\",\"temp_min\",\"precipitation_sum\",\"wind_speed_10m_max\",\"lat\",\"lon\"]:\n",
    "        if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "            issues.append(f\"{col} not numeric\")\n",
    "    print(\"Schema OK.\" if not issues else f\"Validation issues: {issues}\")\n",
    "\n",
    "    # ===== Save interim checked =====\n",
    "    interim_path = f\"{INTERIM_DIR}/checked_{ts}.csv\"\n",
    "    df.to_csv(interim_path, index=False)\n",
    "    print(\"Saved interim:\", interim_path)\n",
    "\n",
    "    # ===== Cleaning =====\n",
    "    dfc = df.copy()\n",
    "    dfc[\"date\"] = pd.to_datetime(dfc[\"date\"], errors=\"coerce\")\n",
    "    dfc = dfc.drop_duplicates([\"city\",\"date\"]).sort_values(\"date\").reset_index(drop=True)\n",
    "    for col, hi in [(\"wind_speed_10m_max\", 120), (\"precipitation_sum\", 200)]:\n",
    "        dfc[col] = np.clip(dfc[col], 0, hi)\n",
    "\n",
    "    clean_path = f\"{PROCESSED_DIR}/clean_{ts}.csv\"\n",
    "    dfc.to_csv(clean_path, index=False)\n",
    "    print(\"Saved clean:\", clean_path)\n",
    "\n",
    "    # ===== Features =====\n",
    "    df_feat = dfc.copy()\n",
    "    df_feat[\"temp_range\"] = df_feat[\"temp_max\"] - df_feat[\"temp_min\"]\n",
    "    df_feat[\"rain_flag\"] = (df_feat[\"precipitation_sum\"] > 0.0).astype(int)\n",
    "    df_feat[\"dow\"] = df_feat[\"date\"].dt.dayofweek\n",
    "\n",
    "    feat_path  = f\"{PROCESSED_DIR}/features_{ts}.csv\"\n",
    "    df_feat.to_csv(feat_path, index=False)\n",
    "    print(\"Saved features:\", feat_path)\n",
    "\n",
    "    # ===== Figures per city =====\n",
    "    %pip install -q kaleido\n",
    "    import plotly.express as px\n",
    "\n",
    "    FIG_DIR = f\"../reports/figures/{city_slug}\"\n",
    "    Path(FIG_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df_feat[\"date\"] = pd.to_datetime(df_feat[\"date\"], errors=\"coerce\")\n",
    "    df_feat[\"date_str\"] = df_feat[\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    fig1 = px.bar(df_feat, x=\"date_str\", y=[\"temp_max\",\"temp_min\"], barmode=\"group\", title=\"Daily Temperatures\")\n",
    "    fig1.update_xaxes(type=\"category\")\n",
    "    fig1.write_image(os.path.join(FIG_DIR, f\"temperatures_{ts}.png\"))\n",
    "    fig1.show()\n",
    "\n",
    "    fig2 = px.line(df_feat, x=\"date_str\", y=\"precipitation_sum\", title=\"Daily Precipitation\")\n",
    "    fig2.update_xaxes(type=\"category\")\n",
    "    fig2.write_image(os.path.join(FIG_DIR, f\"precipitation_{ts}.png\"))\n",
    "    fig2.show()\n",
    "\n",
    "    fig3 = px.line(df_feat, x=\"date_str\", y=\"wind_speed_10m_max\", title=\"Max Wind Speed 10m\")\n",
    "    fig3.update_xaxes(type=\"category\")\n",
    "    fig3.write_image(os.path.join(FIG_DIR, f\"wind_{ts}.png\"))\n",
    "    fig3.show()\n",
    "\n",
    "    print(\"Saved figures to\", FIG_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
